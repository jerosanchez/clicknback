# Prompt: Add an Alembic Migration

Use this prompt when a schema change is needed — adding or removing a table, adding or dropping a column, changing a constraint, adding an index — independently of implementing a full feature.

For schema changes that are part of a new feature or module, the migration step is embedded in `new-feature.prompt.md` (Step 12) and `new-module.prompt.md` (Step 2). Use this prompt only for standalone schema changes.

## Context Files (Read First)

- `alembic.ini` — migration configuration
- `alembic/env.py` — how Alembic connects to the DB and discovers models
- `app/models.py` — the central model registry; all ORM models must be imported here
- The most recent file under `alembic/versions/` — understand the current migration chain before adding to it

## Known Constraints

- Never hand-edit generated migration files under `alembic/versions/` to add application logic. Autogenerated SQL is acceptable to inspect and correct, but the file is always the output of `alembic revision --autogenerate`, not a manual creation.
- Never delete migration files from `alembic/versions/` — the chain must stay intact for rollback to work.
- Every new ORM model must be imported in `app/models.py` before running `alembic revision --autogenerate`, otherwise Alembic will not detect it.
- Do not run `alembic upgrade head` against the production database manually — that is the job of the `migrate` Docker service on deploy.

## Commit Protocol

Stage changes and show a `git diff --staged` summary after the migration is verified. Propose a commit message but do not execute `git commit` until the human explicitly approves. Include the generated migration file in the same commit as any ORM model changes that correspond to it.

---

## Migration Specification

> **Fill this section in before handing to the AI.**

- **Change description:** `<!-- e.g. add cashback_cap column to merchants table -->`
- **Affected table(s):** `<!-- e.g. merchants -->`
- **ORM model changes required:** `<!-- e.g. add cashback_cap: Mapped[float | None] = mapped_column(nullable=True) to Merchant -->`
- **Data migration required:** `<!-- yes/no — if yes, describe: e.g. backfill cashback_cap with default 0.0 for existing rows -->`
- **Index or constraint changes:** `<!-- e.g. add unique constraint on (merchant_id, external_id) -->`
- **Reversibility:** `<!-- Is the downgrade safe? e.g. dropping a nullable column is safe; dropping a non-nullable column with data is destructive -->`

---

## Steps

### Step 1 — Update the ORM model

Apply the specified change to the ORM model in `app/<module>/models.py`. If introducing a new nullable column, annotate it as `Mapped[<type> | None]` with `nullable=True` to ensure the downgrade is safe. If adding a non-nullable column, provide a `server_default` so existing rows are not broken on upgrade.

### Step 2 — Register the model (if new)

If the change involves a brand-new ORM model, import it in `app/models.py`. Alembic's `env.py` uses `Base.metadata` from this registry for schema detection — a model not imported here will be invisible to `autogenerate`.

### Step 3 — Generate the migration

```bash
alembic revision --autogenerate -m "<short description>"
```

Open the generated file in `alembic/versions/`. Read both `upgrade()` and `downgrade()` carefully. Verify:

- The `upgrade()` function contains exactly the intended DDL change — nothing more, nothing less.
- The `downgrade()` function correctly reverses it (e.g., `drop_column` reverses `add_column`).
- No unintended tables or columns appear (this can happen if a model was recently added to `app/models.py` without a prior migration).
- The `down_revision` points to the current head migration.

If `autogenerate` produced incorrect or incomplete SQL, correct it in the migration file before proceeding.

### Step 4 — Apply and verify the upgrade

```bash
alembic upgrade head
```

Then query the affected table to confirm the DDL was applied:

```bash
# Via make db shell or docker exec
SELECT column_name, data_type, is_nullable
FROM information_schema.columns
WHERE table_name = '<table>';
```

### Step 5 — Verify the downgrade round-trip

```bash
alembic downgrade -1
alembic upgrade head
```

Both commands must complete without errors. This verifies the migration is reversible and the downgrade SQL is correct. A migration that cannot be downgraded cleanly is a production risk.

### Step 6 — Data migration (if required)

If the specification includes a data migration (backfilling existing rows), add it as a separate `op.execute()` call inside `upgrade()`, immediately after the DDL change. Data migrations must be idempotent where possible. Document the intent with a comment in the migration file.

### Step 7 — Run quality gates

```bash
make lint && make format && make test
```

Tests should pass unchanged — a schema change that breaks existing tests indicates either a missing default value or a breaking change that was not accounted for in the spec.

### Step 8 — Confirm seeds are still consistent

If `seeds/all.sql` inserts rows into the affected table, verify the SQL is still valid against the new schema. Update the seed file if columns were added (provide the new column value in the `INSERT`) or removed (drop the column from the `INSERT`).
